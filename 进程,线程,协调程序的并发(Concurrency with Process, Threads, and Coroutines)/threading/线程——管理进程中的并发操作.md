目标：管理多个执行线程
使用多线程可以使程序在一个进程空间内运行并发地执行多个操作。
##线程对象
使用一个线程最简单的方式就是用一个目标函数去实例化它并调用start()函数让它开始工作。
```python
# threading_simple.py
import threading


def worker():
    """thread worker function"""
    print('Worker')


threads = []
for i in range(5):
    t = threading.Thread(target=worker)
    threads.append(t)
    t.start()
```
上面程序将会输入五行"Worker"。
```bash
$ python3 threading_simple.py

Worker
Worker
Worker
Worker
Worker
```
##处理当前线程
使用参数来标识或者命名线程将会比较麻烦而且没有这个必要。每一个线程实例都会有一个默认的线程名，而且可以在线程创建的时候修改这个默认值。命名线程在具有不同操作的多个服务线程的服务器进程中十分有用。
```python
# threading_names.py
import threading
import time


def worker():
    print(threading.current_thread().getName(), 'Starting')
    time.sleep(0.2)
    print(threading.current_thread().getName(), 'Exiting')


def my_service():
    print(threading.current_thread().getName(), 'Starting')
    time.sleep(0.3)
    print(threading.current_thread().getName(), 'Exiting')


t = threading.Thread(name='my_service', target=my_service)
w = threading.Thread(name='worker', target=worker)
w2 = threading.Thread(target=worker)  # use default name

w.start()
w2.start()
t.start()

```
调试输出在每一行输出了当前线程的名字。线程名称列中的"Thread-1"对应未命名线程w2。
```bash
$ python3 threading_names.py

worker Starting
Thread-1 Starting
my_service Starting
worker Exiting
Thread-1 Exiting
my_service Exiting
```
大多数程序不会使用打印信息来调试。logging模块支持通过格式化代码`%(threadName)s`在每一条日志信息中嵌入线程名称。在日志信息中加入线程名称，有利于我们追踪信息的来源。
```python
# threading_names_log.py
import logging
import threading
import time


def worker():
    logging.debug('Starting')
    time.sleep(0.2)
    logging.debug('Exiting')


def my_service():
    logging.debug('Starting')
    time.sleep(0.3)
    logging.debug('Exiting')


logging.basicConfig(
    level=logging.DEBUG,
    format='[%(levelname)s] (%(threadName)-10s) %(message)s',
)

t = threading.Thread(name='my_service', target=my_service)
w = threading.Thread(name='worker', target=worker)
w2 = threading.Thread(target=worker)  # use default name

w.start()
w2.start()
t.start()
```
logging是线程安全的，所以来自不同线程的消息在输出中保持不同。
```bash
$ python3 threading_names_log.py

[DEBUG] (worker    ) Starting
[DEBUG] (Thread-1  ) Starting
[DEBUG] (my_service) Starting
[DEBUG] (worker    ) Exiting
[DEBUG] (Thread-1  ) Exiting
[DEBUG] (my_service) Exiting
```
##守护线程 vs 非守护线程
到目前为止，我们的示例程序都会隐式地等待所有线程完成他们的工作之后再退出。有时，程序会产生一个线程作为守护线程，它不会阻止主程序的退出。在服务器中，可能没有简单的方式中断一个线程，这时使用守护线程是十分有用的，或者需要在线程工作到一半的时候挂掉而不会丢失或损坏数据（例如，在服务监控工具中产生“心跳信号”的线程）。将一个线程标志为守护线程，可以在构建它的时候传递参数`daemon=True`，或者调用set_daemon()使用参数True。默认线程不是守护线程。
```python
# threading_daemon.py
import threading
import time
import logging


def daemon():
    logging.debug('Starting')
    time.sleep(0.2)
    logging.debug('Exiting')


def non_daemon():
    logging.debug('Starting')
    logging.debug('Exiting')


logging.basicConfig(
    level=logging.DEBUG,
    format='(%(threadName)-10s) %(message)s',
)

d = threading.Thread(name='daemon', target=daemon, daemon=True)

t = threading.Thread(name='non-daemon', target=non_daemon)

d.start()
t.start()
```
上例的输出中没有守护线程的"Exiting"，因为所有的非守护线程（包括主线程）在守护线程调用sleep()唤醒之前都退出了。
```bash
$ python3 threading_daemon.py

(daemon    ) Starting
(non-daemon) Starting
(non-daemon) Exiting
```
等待守护线程跑完，可以使用join()方法。
```python
threading_daemon_join.py
import threading
import time
import logging


def daemon():
    logging.debug('Starting')
    time.sleep(0.2)
    logging.debug('Exiting')


def non_daemon():
    logging.debug('Starting')
    logging.debug('Exiting')


logging.basicConfig(
    level=logging.DEBUG,
    format='(%(threadName)-10s) %(message)s',
)

d = threading.Thread(name='daemon', target=daemon, daemon=True)

t = threading.Thread(name='non-daemon', target=non_daemon)

d.start()
t.start()

d.join()
t.join()
```
使用join()去等待守护线程退出，意味着它将输出“Exiting”信息。
```bash
$ python3 threading_daemon_join.py

(daemon    ) Starting
(non-daemon) Starting
(non-daemon) Exiting
(daemon    ) Exiting
```
默认地，join()会无限期地阻塞。你也可以传入一个浮点数作为等待线程变为非活动状态等待的秒数。如果在超过这个设定时间后，线程仍未完成，join()会自动返回。
```python
threading_daemon_join_timeout.py
import threading
import time
import logging


def daemon():
    logging.debug('Starting')
    time.sleep(0.2)
    logging.debug('Exiting')


def non_daemon():
    logging.debug('Starting')
    logging.debug('Exiting')


logging.basicConfig(
    level=logging.DEBUG,
    format='(%(threadName)-10s) %(message)s',
)

d = threading.Thread(name='daemon', target=daemon, daemon=True)

t = threading.Thread(name='non-daemon', target=non_daemon)

d.start()
t.start()

d.join(0.1)
print('d.isAlive()', d.isAlive())
t.join()
```
因为传入的超时等待时间小于守护线程在线程中休眠的时间，所以线程在join()返回后依旧还“活着”。
```bash
$ python3 threading_daemon_join_timeout.py

(daemon    ) Starting
(non-daemon) Starting
(non-daemon) Exiting
d.isAlive() True
```
##枚举所有线程
没有必要为所有的守护线程维护一个显式的句柄来确保在主进程退出之前这些守护线程都完成了。enumerate()能够返回一个包含所有活动线程实例的列表。这个列表同时也包括了当前线程，因为等待当前线程结束会进入一种死锁状态，所以必须跳过。
```python
# threading_enumerate.py
import random
import threading
import time
import logging


def worker():
    """thread worker function"""
    pause = random.randint(1, 5) / 10
    logging.debug('sleeping %0.2f', pause)
    time.sleep(pause)
    logging.debug('ending')


logging.basicConfig(
    level=logging.DEBUG,
    format='(%(threadName)-10s) %(message)s',
)

for i in range(3):
    t = threading.Thread(target=worker, daemon=True)
    t.start()

main_thread = threading.main_thread()
for t in threading.enumerate():
    if t is main_thread:
        continue
    logging.debug('joining %s', t.getName())
    t.join()
```
因为worker线程休眠的时间是随机的，所以这个程序的退出时间也是不确定的。
```bash
$ python3 threading_enumerate.py

(Thread-1  ) sleeping 0.20
(Thread-2  ) sleeping 0.30
(Thread-3  ) sleeping 0.40
(MainThread) joining Thread-1
(Thread-1  ) ending
(MainThread) joining Thread-3
(Thread-2  ) ending
(Thread-3  ) ending
(MainThread) joining Thread-2
```
##派生线程
开始时，线程会做一些初始化工作，然后调用run()，在run()中调用传递给构造函数的目标函数。如果要创建一个Thread的子类，需要覆盖run()来完成所需要的工作。
```python
# threading_subclass.py
import threading
import logging


class MyThread(threading.Thread):

    def run(self):
        logging.debug('running')


logging.basicConfig(
    level=logging.DEBUG,
    format='(%(threadName)-10s) %(message)s',
)

for i in range(5):
    t = MyThread()
    t.start()
```
忽略run()的返回值。
```bash
$ python3 threading_subclass.py

(Thread-1  ) running
(Thread-2  ) running
(Thread-3  ) running
(Thread-4  ) running
(Thread-5  ) running
```
因为传递给Thread构造函数的args和kwargs值是存储在私有变量（前缀'__'的变量）中的。，子类并不能简单地访问这些变量。如果要向一个定制线程传递参数，应该在重新定义的构造函数中将这些值保存在一个子类可见的实例属性中。

```python
# threading_subclass_args.py
import threading
import logging


class MyThreadWithArgs(threading.Thread):

    def __init__(self, group=None, target=None, name=None,
                 args=(), kwargs=None, *, daemon=None):
        super().__init__(group=group, target=target, name=name,
                         daemon=daemon)
        self.args = args
        self.kwargs = kwargs

    def run(self):
        logging.debug('running with %s and %s',
                      self.args, self.kwargs)


logging.basicConfig(
    level=logging.DEBUG,
    format='(%(threadName)-10s) %(message)s',
)

for i in range(5):
    t = MyThreadWithArgs(args=(i,), kwargs={'a': 'A', 'b': 'B'})
    t.start()
```
MyThreadWithArgs使用的API和Thread一样，但这个类可以简单地通过修改构造函数方法，使其可以接收更多与线程用途直接相关的不同参数，这一点类似于其他定制类。
```bash
$ python3 threading_subclass_args.py

(Thread-1  ) running with (0,) and {'b': 'B', 'a': 'A'}
(Thread-2  ) running with (1,) and {'b': 'B', 'a': 'A'}
(Thread-3  ) running with (2,) and {'b': 'B', 'a': 'A'}
(Thread-4  ) running with (3,) and {'b': 'B', 'a': 'A'}
(Thread-5  ) running with (4,) and {'b': 'B', 'a': 'A'}
```
##定时器线程
线程子类的一个示例是由Timer提供的，也包括在Threading中。定时器线程会在一段时间延时之后再开始它的线程工作，并且也能在定时周期内的任何时间点停止。
```python
# threading_timer.py
import threading
import time
import logging


def delayed():
    logging.debug('worker running')


logging.basicConfig(
    level=logging.DEBUG,
    format='(%(threadName)-10s) %(message)s',
)

t1 = threading.Timer(0.3, delayed)
t1.setName('t1')
t2 = threading.Timer(0.3, delayed)
t2.setName('t2')

logging.debug('starting timers')
t1.start()
t2.start()

logging.debug('waiting before canceling %s', t2.getName())
time.sleep(0.2)
logging.debug('canceling %s', t2.getName())
t2.cancel()
logging.debug('done')

```
在上面的示例中，第二个定时器线程内容永远都不会执行，第一个定时器线程会在主程序执行完之后再执行线程工作。由于它不是一个守护线程，所有在主线程退出以后它也会隐式地退出。
```bash
$ python3 threading_timer.py

(MainThread) starting timers
(MainThread) waiting before canceling t2
(MainThread) canceling t2
(MainThread) done
(t1        ) worker running
```
##线程间通信
虽然使用多线程的主要目的是同时执行不同操作，但有时候在多线程中同步一个或多个操作也是很重要的。Event对象提供了一种简单的方式可以让我们在线程之间安全地通讯。一个Event会在内部管理一个标志，调用者可以通过set()和clear()方法控制这个标志。其他线程可以使用wait()来暂停自己当前的操作，等待这个标志置位，这样能有效地阻塞线程直到操作允许被执行。
```python
# threading_event.py
import logging
import threading
import time


def wait_for_event(e):
    """Wait for the event to be set before doing anything"""
    logging.debug('wait_for_event starting')
    event_is_set = e.wait()
    logging.debug('event set: %s', event_is_set)


def wait_for_event_timeout(e, t):
    """Wait t seconds and then timeout"""
    while not e.is_set():
        logging.debug('wait_for_event_timeout starting')
        event_is_set = e.wait(t)
        logging.debug('event set: %s', event_is_set)
        if event_is_set:
            logging.debug('processing event')
        else:
            logging.debug('doing other work')


logging.basicConfig(
    level=logging.DEBUG,
    format='(%(threadName)-10s) %(message)s',
)

e = threading.Event()
t1 = threading.Thread(
    name='block',
    target=wait_for_event,
    args=(e,),
)
t1.start()

t2 = threading.Thread(
    name='nonblock',
    target=wait_for_event_timeout,
    args=(e, 2),
)
t2.start()

logging.debug('Waiting before calling Event.set()')
time.sleep(0.3)
e.set()
logging.debug('Event is set')
```
wait()可以接收一个参数作为超时等待时间（秒）。它会返回一个布尔值表示event是否置位，以便于调用者知道wait()是因为什么而返回的。is_set()可以单独使用在event上而不用担心阻塞。
在上例中，wait_for_event_timeout()查看event的状态时不会无限期地阻塞。wait_for_event()在调用wait()的时候会阻塞直到event状态发生变化返回。
```bash
$ python3 threading_event.py

(block     ) wait_for_event starting
(nonblock  ) wait_for_event_timeout starting
(MainThread) Waiting before calling Event.set()
(MainThread) Event is set
(nonblock  ) event set: True
(nonblock  ) processing event
(block     ) event set: True
```
##资源访问控制
除了线程之间的同步操作之外，控制线程之间对共享资源的访问也同样重要，这能防止数据的冲突或丢失。Python内建的数据结构（列表，字典等）是线程安全的，这个Python使用原子字节码来管理这些数据结构的一个副作用（保护Python内部数据结构的GIL不会在更新的过程中释放）。其他的Python数据结构，如简单的integer和float，它们就没有这类保护措施。为了防止同时访问同一个对象，可以使用一个Lock对象。
```python
# threading_lock.py
import logging
import random
import threading
import time


class Counter:

    def __init__(self, start=0):
        self.lock = threading.Lock()
        self.value = start

    def increment(self):
        logging.debug('Waiting for lock')
        self.lock.acquire()
        try:
            logging.debug('Acquired lock')
            self.value = self.value + 1
        finally:
            self.lock.release()


def worker(c):
    for i in range(2):
        pause = random.random()
        logging.debug('Sleeping %0.02f', pause)
        time.sleep(pause)
        c.increment()
    logging.debug('Done')


logging.basicConfig(
    level=logging.DEBUG,
    format='(%(threadName)-10s) %(message)s',
)

counter = Counter()
for i in range(2):
    t = threading.Thread(target=worker, args=(counter,))
    t.start()

logging.debug('Waiting for worker threads')
main_thread = threading.main_thread()
for t in threading.enumerate():
    if t is not main_thread:
        t.join()
logging.debug('Counter: %d', counter.value)
```
在上例中，worker()函数使一个Counter实例递增，这个实例会管理一个Lock防止两个线程在同一时间点修改自己的内部状态。如果不使用Lock，有可能会丢失一次对value属性的修改。
```bash
$ python3 threading_lock.py

(Thread-1  ) Sleeping 0.18
(Thread-2  ) Sleeping 0.93
(MainThread) Waiting for worker threads
(Thread-1  ) Waiting for lock
(Thread-1  ) Acquired lock
(Thread-1  ) Sleeping 0.11
(Thread-1  ) Waiting for lock
(Thread-1  ) Acquired lock
(Thread-1  ) Done
(Thread-2  ) Waiting for lock
(Thread-2  ) Acquired lock
(Thread-2  ) Sleeping 0.81
(Thread-2  ) Waiting for lock
(Thread-2  ) Acquired lock
(Thread-2  ) Done
(MainThread) Counter: 4
```
我们可以在调用acquire()方法时对阻塞参数传入False，这样我们在检查是否有其他线程获得Lock的同时而又不会线程挂起。在下一个示例中，worker()会尝试三次去获得Lock，并计算它必须进行多少次尝试。同时，lock_holder()在保持和释放Lock之间，每个状态都会持续一段时间周期，以此来模拟负载。
```python
# threading_lock_noblock.py
import logging
import threading
import time


def lock_holder(lock):
    logging.debug('Starting')
    while True:
        lock.acquire()
        try:
            logging.debug('Holding')
            time.sleep(0.5)
        finally:
            logging.debug('Not holding')
            lock.release()
        time.sleep(0.5)


def worker(lock):
    logging.debug('Starting')
    num_tries = 0
    num_acquires = 0
    while num_acquires < 3:
        time.sleep(0.5)
        logging.debug('Trying to acquire')
        have_it = lock.acquire(0)
        try:
            num_tries += 1
            if have_it:
                logging.debug('Iteration %d: Acquired',
                              num_tries)
                num_acquires += 1
            else:
                logging.debug('Iteration %d: Not acquired',
                              num_tries)
        finally:
            if have_it:
                lock.release()
    logging.debug('Done after %d iterations', num_tries)


logging.basicConfig(
    level=logging.DEBUG,
    format='(%(threadName)-10s) %(message)s',
)

lock = threading.Lock()

holder = threading.Thread(
    target=lock_holder,
    args=(lock,),
    name='LockHolder',
    daemon=True,
)
holder.start()

worker = threading.Thread(
    target=worker,
    args=(lock,),
    name='Worker',
)
worker.start()
```
worker()在3次获得lock的过程中，进行了超过3次的迭代尝试。
```bash
$ python3 threading_lock_noblock.py

(LockHolder) Starting
(LockHolder) Holding
(Worker    ) Starting
(LockHolder) Not holding
(Worker    ) Trying to acquire
(Worker    ) Iteration 1: Acquired
(LockHolder) Holding
(Worker    ) Trying to acquire
(Worker    ) Iteration 2: Not acquired
(LockHolder) Not holding
(Worker    ) Trying to acquire
(Worker    ) Iteration 3: Acquired
(LockHolder) Holding
(Worker    ) Trying to acquire
(Worker    ) Iteration 4: Not acquired
(LockHolder) Not holding
(Worker    ) Trying to acquire
(Worker    ) Iteration 5: Acquired
(Worker    ) Done after 5 iterations
```
####重入锁
正常的Lock对象不能被获取超过一次，即使是同一个线程。如果一个锁在同一个调用链中被多个函数访问，这样的限制可能会引起我们不想要的副作用。
```python
# threading_lock_reacquire.py
import threading

lock = threading.Lock()

print('First try :', lock.acquire())
print('Second try:', lock.acquire(0))
```
在这种情况下，我们在第二次调用acquire()的时候给了一个参数0作为超时参数，以防函数一直被阻塞，因为第一次调用的时候就一直把这个锁占用了。
```bash
$ python3 threading_lock_reacquire.py

First try : True
Second try: False
```
对于在同一线程下需不同的代码需要重新获取锁的情况，我们可以使用RLock。
```python
# threading_rlock.py
import threading

lock = threading.RLock()

print('First try :', lock.acquire())
print('Second try:', lock.acquire(0))
```
与之前代码不同的地方，仅仅是用RLock替代了Lock。
```bash
$ python3 threading_rlock.py

First try : True
Second try: True
```
##作为上下文管理器的锁
Lock实现了上下文管理器的API，并与with语句兼容。使用with语句就可以不需要显式地获取和释放锁。
```python
# threading_lock_with.py
import threading
import logging


def worker_with(lock):
    with lock:
        logging.debug('Lock acquired via with')


def worker_no_with(lock):
    lock.acquire()
    try:
        logging.debug('Lock acquired directly')
    finally:
        lock.release()


logging.basicConfig(
    level=logging.DEBUG,
    format='(%(threadName)-10s) %(message)s',
)

lock = threading.Lock()
w = threading.Thread(target=worker_with, args=(lock,))
nw = threading.Thread(target=worker_no_with, args=(lock,))

w.start()
nw.start()
```
worker_with()和worker_no_with()分别以相应的方式管理锁。
```bash
$ python3 threading_lock_with.py

(Thread-1  ) Lock acquired via with
(Thread-2  ) Lock acquired directly
```
#同步线程
除了使用Event意外，还有一种同步线程的方式，就是使用Condition对象。因为Condition使用了一个可以绑定到共享资源的Lock，并允许多个线程等待资源更新。在下面的例子中，consumer()线程需要等待Condition置位才能继续。producer()线程则负责置位condition并通知其他线程可以继续它们的工作。
```python
# threading_condition.py
import logging
import threading
import time


def consumer(cond):
    """wait for the condition and use the resource"""
    logging.debug('Starting consumer thread')
    with cond:
        cond.wait()
        logging.debug('Resource is available to consumer')


def producer(cond):
    """set up the resource to be used by the consumer"""
    logging.debug('Starting producer thread')
    with cond:
        logging.debug('Making resource available')
        cond.notifyAll()


logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s (%(threadName)-2s) %(message)s',
)

condition = threading.Condition()
c1 = threading.Thread(name='c1', target=consumer,
                      args=(condition,))
c2 = threading.Thread(name='c2', target=consumer,
                      args=(condition,))
p = threading.Thread(name='p', target=producer,
                     args=(condition,))

c1.start()
time.sleep(0.2)
c2.start()
time.sleep(0.2)
p.start()
```
线程使用with语句去获取Condition相关的lock。当然显式地调用acquire()和release()方法也是可行的。
```bash
$ python3 threading_condition.py

2016-07-10 10:45:28,170 (c1) Starting consumer thread
2016-07-10 10:45:28,376 (c2) Starting consumer thread
2016-07-10 10:45:28,581 (p ) Starting producer thread
2016-07-10 10:45:28,581 (p ) Making resource available
2016-07-10 10:45:28,582 (c1) Resource is available to consumer
2016-07-10 10:45:28,582 (c2) Resource is available to consumer
```
Barrier是另外一种线程同步的机制。一个Barrier会建立一个控制点，所有参与的线程都将阻塞，直到它们参与的某一部分达到那个控制点。线程单独启动，然后暂停，直到他们都准备好继续运行。
```python
# threading_barrier.py
import threading
import time


def worker(barrier):
    print(threading.current_thread().name,
          'waiting for barrier with {} others'.format(
              barrier.n_waiting))
    worker_id = barrier.wait()
    print(threading.current_thread().name, 'after barrier',
          worker_id)


NUM_THREADS = 3

barrier = threading.Barrier(NUM_THREADS)

threads = [
    threading.Thread(
        name='worker-%s' % i,
        target=worker,
        args=(barrier,),
    )
    for i in range(NUM_THREADS)
]

for t in threads:
    print(t.name, 'starting')
    t.start()
    time.sleep(0.1)

for t in threads:
    t.join()
```
在上面的例子中，Barrier被配置为阻塞状态，直到三个线程都在等待则激活。当条件满足了，所有线程都在同一时间释放传递控制点。wait()方法的返回值代表释放部分的数字，可以用于限制一些线程采取清除共享资源的操作。
```bash
$ python3 threading_barrier.py

worker-0 starting
worker-0 waiting for barrier with 0 others
worker-1 starting
worker-1 waiting for barrier with 1 others
worker-2 starting
worker-2 waiting for barrier with 2 others
worker-2 after barrier 2
worker-0 after barrier 0
worker-1 after barrier 1
```
Barrier的abort()方法会引起所有等待线程收到一个BrokenBarrierError的异常。它会清除阻塞在wait()且处理过程停止的线程。
```python
# threading_barrier_abort.py
import threading
import time


def worker(barrier):
    print(threading.current_thread().name,
          'waiting for barrier with {} others'.format(
              barrier.n_waiting))
    try:
        worker_id = barrier.wait()
    except threading.BrokenBarrierError:
        print(threading.current_thread().name, 'aborting')
    else:
        print(threading.current_thread().name, 'after barrier',
              worker_id)


NUM_THREADS = 3

barrier = threading.Barrier(NUM_THREADS + 1)

threads = [
    threading.Thread(
        name='worker-%s' % i,
        target=worker,
        args=(barrier,),
    )
    for i in range(NUM_THREADS)
]

for t in threads:
    print(t.name, 'starting')
    t.start()
    time.sleep(0.1)

barrier.abort()

for t in threads:
    t.join()
```
上例中，我们将Barrier配置成四个线程，比我们实际启动的线程数多一个，因此例子中所有启动的线程都会被阻塞。
```bash
$ python3 threading_barrier_abort.py

worker-0 starting
worker-0 waiting for barrier with 0 others
worker-1 starting
worker-1 waiting for barrier with 1 others
worker-2 starting
worker-2 waiting for barrier with 2 others
worker-0 aborting
worker-2 aborting
worker-1 aborting
```

















